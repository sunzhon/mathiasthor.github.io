<!DOCTYPE html>
<html>

  <head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width initial-scale=1" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge">

  <title>Mathias Thor | Publications</title>
  <meta name="description" content="A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design.
">

  <link rel="shortcut icon" href="/assets/img/favicon.ico">

  <link rel="stylesheet" href="/assets/css/main.css">
  <link rel="canonical" href="/publications/">
</head>


  <body>

    <header class="site-header">

  <div class="wrapper">

    
    <span class="site-title">
        
        <strong>Mathias</strong> Thor
    </span>
    

    <nav class="site-nav">
      <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path fill="#424242" d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.031C17.335,0,18,0.665,18,1.484L18,1.484z"/>
              <path fill="#424242" d="M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0c0-0.82,0.665-1.484,1.484-1.484 h15.031C17.335,6.031,18,6.696,18,7.516L18,7.516z"/>
              <path fill="#424242" d="M18,13.516C18,14.335,17.335,15,16.516,15H1.484C0.665,15,0,14.335,0,13.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.031C17.335,12.031,18,12.696,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

      <div class="trigger">
        <!-- About -->
        <a class="page-link" href="/">Home</a>

        <!-- Pages -->
        
          
        
          
            <a class="page-link" href="/events/">Events</a>
          
        
          
        
          
        
          
            <a class="page-link" href="/publications/">Publications</a>
          
        
          
            <a class="page-link" href="/tutorials/">Tutorials</a>
          
        
          
        
          
        

        <!-- Blog -->
        <a class="page-link" href="/blog/">Blog</a>

        <!-- CV link -->
        <a class="page-link" href="/assets/pdf/CV_MathiasThor.pdf">CV</a>

      </div>
    </nav>

  </div>

</header>



    <div class="page-content">
      <div class="wrapper">
        <div class="post">

  <header class="post-header">
    <h1 class="post-title">Publications</h1>
    <h5 class="post-description">Publications by categories in reverse chronological order.</h5>
  </header>

  <article class="post-content Publications clearfix">
    
<h3 class="year">2020</h3>
<ol class="bibliography"><li>

<div id="CPGRBFNsub">
  
    <span class="title"><b>Generic Neural Locomotion Control Framework for Legged Robots</b></span>
    <span class="author">
      
        
          
            <em>M. Thor</em>,
          
        
      
        
          
            
              T. Kulvicius,
            
          
        
      
        
          and
          
            
              P. Manoonpong
            
          
        
      
    </span>

    <span class="periodical">
    
      <em>IEEE Transactions on Neural Networks and Learning Systems</em>
    
    
      2020
    

    </span>
  



  <span class="publication-links">
  
    <a class="abstract">Abstract</a>
  
  
  
  
  
  
  
  
  
  
    <em style="color:#17A589"> &#160; <i class="fas fa-book"></i> Journal paper </em>
  
  
  
  
    <em style="color:#5D6D7E"> &#160; <i class="fas fa-seedling"></i> Under Review </em>
  
  
  </span>

  <!-- Hidden abstract block -->
  
  <span class="abstract hidden">
    <p>In this paper, we present a generic locomotion control framework for legged robots and a strategy for control policy optimization. The framework is based on neural control and black-box optimization. The neural control combines a central pattern generator (CPG) and a radial basis function (RBF) network into a CPG-RBF network. The control network acts as a neural basis that can produce arbitrary rhythmic trajectories for the joints of robots. The main features of the CPG-RBF network are: 1) it is generic as it can be applied to legged robots with different morphologies; 2) it has few control parameters, resulting in fast learning; 3) it is scalable both in terms of policy/trajectory complexity and the number of legs that can be controlled using similar trajectories; 4) it does not rely on sensory feedback to generate locomotion and is thus less prone to sensory faults; 5) finally, once trained, it is simple, minimal, and intuitive to use and analyze. To the best of our knowledge, all these features have not been previously addressed by any other control frameworks or control techniques. These features will lead to an easy-to-use framework with fast convergence and the ability to encode complex locomotion control policies (or motor primitives) without the need for sensory feedback. In this work, we show that the framework can successfully be applied to three different simulated legged robots with varying morphologies and even broken joints to learn locomotion control policies. Furthermore, we show that after learning, the control policies can also be successfully transferred to a real-world robot without any modifications. Finally, we also show the scalability of the framework by implementing it as a central controller for all legs of a robot and as a decentralized controller for individual legs and leg pairs (i.e., front, hind, and middle legs). We call these indirect, direct, and semi-indirect encodings, respectively. By investigating the correlation between robot morphology and encoding type, we are also able to present a strategy for control policy optimization.</p>
  </span>
  

</div>

<!-- https://htmlcolorcodes.com/ -->
<!-- https://fontawesome.com/icons/graduation-cap?style=solid -->
</li></ol>

<h3 class="year">2019</h3>
<ol class="bibliography"><li>

<div id="10.1007/978-3-030-30487-4_53">
  
    <span class="title"><b>CPG Driven RBF Network Control with Reinforcement Learning for Gait Optimization of a Dung Beetle-Like Robot</b></span>
    <span class="author">
      
        
          
            
              Matheshwaran Pitchai,
            
          
        
      
        
          
            
              Xiaofeng Xiong,
            
          
        
      
        
          
            <em>Mathias Thor</em>,
          
        
      
        
          
            
              Peter Billeschou,
            
          
        
      
        
          
            
              Peter Lukas Mailänder,
            
          
        
      
        
          
            
              Binggwong Leung,
            
          
        
      
        
          
            
              Tomas Kulvicius,
            
          
        
      
        
          and
          
            
              Poramate Manoonpong
            
          
        
      
    </span>

    <span class="periodical">
    
      <em>In Artificial Neural Networks and Machine Learning – ICANN 2019: Theoretical Neural Computation</em>
    
    
      2019
    

    </span>
  



  <span class="publication-links">
  
    <a class="abstract">Abstract</a>
  
  
    [<a href="https://link.springer.com/chapter/10.1007/978-3-030-30487-4_53" target="_blank">HTML</a>]
  
  
  
  
  
  
  
  
  
  
    <em style="color:#AF7AC5"> &#160; <i class="fas fa-users"></i> Conference paper </em>
  
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
  <span class="abstract hidden">
    <p>In this paper, we employ a central pattern generator (CPG) driven radial basis function network (RBFN) based controller to learn optimized locomotion for a complex dung beetle-like robot using reinforcement learning approach called “Policy Improvement with Path Integrals (PI²)”. Our CPG driven RBFN controller is inspired by rhythmic dynamic movement primitives (DMPs). The controller can be also seen as an extension to a traditional CPG controller, which usually controls only the frequency of the motor patterns but not the shape. Our controller uses the CPG to control the frequency while the RBFN takes care of the shape of the motor patterns. In this paper, we only focus on the shape of the motor patterns and optimize those with respect to walking speed and energy efficiency. As a result, the robot can travel faster and consume less power than using only the CPG controller.</p>
  </span>
  

</div>

<!-- https://htmlcolorcodes.com/ -->
<!-- https://fontawesome.com/icons/graduation-cap?style=solid -->
</li>
<li>

<div id="bingamam">
  
    <span class="title"><b>Modular Neural Control for Dung Beetle-like Leg Movements of a Dung Beetle-like Robot</b></span>
    <span class="author">
      
        
          
            
              Binggwong Leung,
            
          
        
      
        
          
            
              Peter Billeschou,
            
          
        
      
        
          
            <em>Mathias Thor</em>,
          
        
      
        
          and
          
            
              Poramate Manoonpong
            
          
        
      
    </span>

    <span class="periodical">
    
      <em>In The 9th International Symposium on Adaptive Motion of Animals and Machines (AMAM 2019)</em>
    
    
      2019
    

    </span>
  



  <span class="publication-links">
  
    <a class="abstract">Abstract</a>
  
  
    [<a href="https://infoscience.epfl.ch/record/272146" target="_blank">HTML</a>]
  
  
  
  
  
  
  
  
  
  
    <em style="color:#AF7AC5"> &#160; <i class="fas fa-users"></i> Conference paper </em>
  
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
  <span class="abstract hidden">
    <p>Dung beetles can perform impressive multiple motor behaviors using their legs. The behaviors include walking and rolling a large dung ball on different terrains, e.g., level ground and different slopes. To achieve such complex behaviors for legged robots, we propose here a modular neural controller for dung beetle-like locomotion and object transportation behaviors of a dung beetle-like robot. The modular controller consists of several modules based on three generic neural modules. The main modules include 1) a neural oscillator network module (as a central pattern generator (CPG)), 2) a neural CPG postprocessing module (PCPG), 3) a velocity regulating network module (VRN). The CPG generates basic rhythmic patterns. The patterns are first shaped by the PCPG and their amplitudes as well as phases are later modified by the VRN to obtain proper motor patterns for locomotion and object transportation. Combining all these neural modules, we can achieve different motor patterns for four different actions which are forward walking, backward walking, levelground ball rolling, and sloped-ground ball rolling. All these actions can be activated by four input neurons. The experimental results show that the simulated dung beetle-like robot can robustly perform the actions. The average forward speed is 0.058 cm/s and the robot is able to roll a large ball (about 3 times of its body height and 2 times of its weight) up different slope angles up to 25 degrees.</p>
  </span>
  

</div>

<!-- https://htmlcolorcodes.com/ -->
<!-- https://fontawesome.com/icons/graduation-cap?style=solid -->
</li>
<li>

<div id="8754697">
  
    <span class="title"><b>A Fast Online Frequency Adaptation Mechanism for CPG-Based Robot Motion Control</b></span>
    <span class="author">
      
        
          
            <em>M. Thor</em>,
          
        
      
        
          and
          
            
              P. Manoonpong
            
          
        
      
    </span>

    <span class="periodical">
    
      <em>IEEE Robotics and Automation Letters</em>
    
    
      2019
    

    </span>
  



  <span class="publication-links">
  
    <a class="abstract">Abstract</a>
  
  
    [<a href="https://ieeexplore.ieee.org/document/8754697" target="_blank">HTML</a>]
  
  
  
  
  
  
  
  
  
    <em style="color:#17A589"> &#160; <i class="fas fa-book"></i> Journal paper </em>
  
  
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
  <span class="abstract hidden">
    <p>In this letter, we present an online learning mechanism called the dual integral learner for fast frequency adaptation in neural central pattern generator (CPG) based locomotion control of a hexapod robot. The mechanism works by modulating the CPG frequency through synaptic plasticity of the neural CPG network. The modulation is based on tracking error feedback between the CPG output and joint angle sensory feedback of the hexapod robot. As a result, the mechanism will always try to match the CPG frequency to the walking performance of the robot, thereby ensuring that the entire generated trajectory can be followed with low tracking error. Real robot experiments show that our mechanism can automatically generate a proper walking frequency for energy-efficient locomotion with respect to the robot body as well as being able to quickly adapt the frequency online within a few seconds to deal with external perturbations such as leg blocking and a variation in electrical power. These important features will allow a hexapod robot to be more robust and also extend its operating time. Finally, the generality of the mechanism is shown by successfully applying it to a compliant robotic manipulator arm called GummiArm.</p>
  </span>
  

</div>

<!-- https://htmlcolorcodes.com/ -->
<!-- https://fontawesome.com/icons/graduation-cap?style=solid -->
</li>
<li>

<div id="8787876">
  
    <span class="title"><b>Error-Based Learning Mechanism for Fast Online Adaptation in Robot Motor Control</b></span>
    <span class="author">
      
        
          
            <em>M. Thor</em>,
          
        
      
        
          and
          
            
              P. Manoonpong
            
          
        
      
    </span>

    <span class="periodical">
    
      <em>IEEE Transactions on Neural Networks and Learning Systems</em>
    
    
      2019
    

    </span>
  



  <span class="publication-links">
  
    <a class="abstract">Abstract</a>
  
  
    [<a href="https://ieeexplore.ieee.org/document/8787876" target="_blank">HTML</a>]
  
  
  
  
  
  
  
  
  
    <em style="color:#17A589"> &#160; <i class="fas fa-book"></i> Journal paper </em>
  
  
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
  <span class="abstract hidden">
    <p>Existing state-of-the-art frequency adaptation mechanisms of central pattern generators (CPGs) for robot locomotion control typically rely on correlation-based learning. They do not account for the tracking error that may occur between the actual system motion and CPG output, leading to the loss of precision, unwanted movement, inefficient energy locomotion, and in the worst cases, motor collapse. To overcome this problem, we developed online error-based learning for frequency adaptation of CPGs. The learning mechanism used for error reduction is a novel modification of the dual learner (DL) called dual integral learner (DIL). Being able to reduce tracking and steady-state errors, it can also perform fast and stable learning, adapting the CPG frequency to match the performance of robotic systems. Control parameters of the DIL are more straightforward for complex systems (like walking robots), compared to traditional correlation-based learning, since they correspond to error reduction. Due to its embedded memory, the DIL can relearn quickly and recover spontaneously from the previously learned parameters. All these features are not covered by the existing frequency adaptation mechanisms. We integrated the DIL into a neural CPG-based motor control system for use on different legged robots with various morphologies for evaluation. The results show that: 1) the DIL does not require precise adjustment of its parameters to fit specific robots; and 2) the DIL can automatically and quickly adapt the CPG frequency to the robots such that the entire trajectory of the CPG can be precisely followed with very low tracking and steady-state errors. Consequently, the robots can perform the desired movements with more energy-efficient locomotion compared to the state-of-the-art correlation-based learning mechanism called frequency adaptation through fast dynamical coupling (AFDC). In the future, the proposed error-based learning mechanism for fast online adaptation in robot motor control can be used as a basis for trajectory optimization, universal controllers, and other studies concerning the change of intrinsic or extrinsic parameters.</p>
  </span>
  

</div>

<!-- https://htmlcolorcodes.com/ -->
<!-- https://fontawesome.com/icons/graduation-cap?style=solid -->
</li>
<li>

<div id="thormaster">
  
    <span class="title"><b>MORF - Modular Robot Framework</b></span>
    <span class="author">
      
    </span>

    <span class="periodical">
    
      <em>University of Southern Denmark - Campusvej 55, 5230 Odense, Denmark</em>
    
    
      2019
    

    </span>
  



  <span class="publication-links">
  
  
  
    [<a href="/assets/pdf/MORF_master.pdf" target="_blank">PDF</a>]
  
  
  
  
  
  
  
  
  
  
    <em style="color:#3498DB"> &#160; <i class="fas fa-graduation-cap"></i> Master Thesis </em>
  
  
  
	<em class="Best Paper Award">
	  <em style="color:#F39C12"> &#160; <i class="fas fa-trophy"></i> Top grade </em>
	</em>
  
  </span>

  <!-- Hidden abstract block -->
  

</div>

<!-- https://htmlcolorcodes.com/ -->
<!-- https://fontawesome.com/icons/graduation-cap?style=solid -->
</li></ol>

<h3 class="year">2018</h3>
<ol class="bibliography"><li>

<div id="Thor_2018">
  
    <span class="title"><b>A dung beetle-inspired robotic model and its distributed sensor-driven control for walking and ball rolling</b></span>
    <span class="author">
      
        
          
            <em>M. Thor</em>,
          
        
      
        
          
            
              T. Strøm-Hansen,
            
          
        
      
        
          
            
              L. B. Larsen,
            
          
        
      
        
          
            
              A. Kovalev,
            
          
        
      
        
          
            
              S. N. Gorb,
            
          
        
      
        
          
            
              E. Baird,
            
          
        
      
        
          and
          
            
              P. Manoonpong
            
          
        
      
    </span>

    <span class="periodical">
    
      <em>Artificial Life and Robotics</em>
    
    
      2018
    

    </span>
  



  <span class="publication-links">
  
    <a class="abstract">Abstract</a>
  
  
    [<a href="https://doi.org/10.1007%2Fs10015-018-0456-8" target="_blank">HTML</a>]
  
  
  
  
  
  
  
  
  
    <em style="color:#17A589"> &#160; <i class="fas fa-book"></i> Journal paper </em>
  
  
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
  <span class="abstract hidden">
    <p>A typical approach when designing a bio-inspired robot is to simplify an animal model and to enhance the functionality of interest. For hexapod robots, this often leads to a need of supplementary mechanics to become multifunctional. However, a preferable solution is to employ the embodied multifunctional capabilities of the animal as inspiration for robot design. Using this approach, we present a method for translating the kinematic chain of a dung beetle from which an accurate kinematic model and a simplified one were simulated and compared. The beetle was selected due to its multifunctional locomotory capabilities including walking as well as standing on and rolling a ball. For testing the models, we developed a distributed sensor-driven controller that can generate walking and ball-rolling behaviors. A comparison of the two modeling approaches shows a similar performance with regards to walking stability and accuracy, but differences when it comes to speed and multifunctionality. This is because the accurate model is able to use its legs to walk faster and roll a ball, which the simplified one is not. In conclusion, the accurate model of a dung beetle-inspired robot is advantageous as it, together with our novel control mechanism, is able to elicit behaviors comparable to those of the real dung beetle (i.e., walking and rolling a dung ball).</p>
  </span>
  

</div>

<!-- https://htmlcolorcodes.com/ -->
<!-- https://fontawesome.com/icons/graduation-cap?style=solid -->
</li>
<li>

<div id="0c6c73aae6a44145b48f58fbb645110e">
  
    <span class="title"><b>Modular neural control for bio-inspired walking and ball rolling of a dung beetle-like robot</b></span>
    <span class="author">
      
        
          
            
              Binggwong Leung,
            
          
        
      
        
          
            <em>Mathias Thor</em>,
          
        
      
        
          and
          
            
              Poramate Manoonpong
            
          
        
      
    </span>

    <span class="periodical">
    
      <em>In ALife 2018</em>
    
    
      2018
    

    </span>
  



  <span class="publication-links">
  
    <a class="abstract">Abstract</a>
  
  
    [<a href="https://www.mitpressjournals.org/doi/abs/10.1162/isal_a_00064" target="_blank">HTML</a>]
  
  
    [<a href="/assets/pdf/ALIFE_2018_bing.pdf" target="_blank">PDF</a>]
  
  
  
  
  
  
  
  
  
    <em style="color:#AF7AC5"> &#160; <i class="fas fa-users"></i> Conference paper </em>
  
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
  <span class="abstract hidden">
    <p>Dung beetles can perform impressive multiple motor behaviors using their legs. The behaviors include walking and rolling a large dung ball on different terrains, e.g., level ground and different slopes. To achieve such complex behaviors for legged robots, we propose here a modular neural controller for dung beetle-like locomotion and object transportation behaviors of a dung beetle-like robot. The modular controller consists of several modules based on three generic neural modules. The main modules include 1) a neural oscillator network module (as a central pattern generator (CPG)), 2) a neural CPG postprocessing module (PCPG), 3) a velocity regulating network module (VRN). The CPG generates basic rhythmic patterns. The patterns are first shaped by the PCPG and their amplitudes as well as phases are later modified by the VRN to obtain proper motor patterns for locomotion and object transportation. Combining all these neural modules, we can achieve different motor patterns for four different actions which are forward walking, backward walking, levelground ball rolling, and sloped-ground ball rolling. All these actions can be activated by four input neurons. The experimental results show that the simulated dung beetle-like robot can robustly perform the actions. The average forward speed is 0.058 cm/s and the robot is able to roll a large ball (about 3 times of its body height and 2 times of its weight) up different slope angles up to 25 degrees.</p>
  </span>
  

</div>

<!-- https://htmlcolorcodes.com/ -->
<!-- https://fontawesome.com/icons/graduation-cap?style=solid -->
</li>
<li>

<div id="MORF">
  
    <span class="title"><b>MORF - Modular Robot Framework</b></span>
    <span class="author">
      
        
          
            <em>Mathias Thor</em>,
          
        
      
        
          
            
              Jørgen Christian Larsen,
            
          
        
      
        
          and
          
            
              Poramate Manoonpong
            
          
        
      
    </span>

    <span class="periodical">
    
      <em>In The 2nd International Youth Conference of Bionic Engineering (IYCBE 2018)</em>
    
    
      2018
    

    </span>
  



  <span class="publication-links">
  
  
    [<a href="https://www.frontiersin.org/books/The_2nd_International_Youth_Conference_of_Bionic_Engineering_IYCBE_2018/1718" target="_blank">HTML</a>]
  
  
  
  
  
  
  
  
  
  
    <em style="color:#AF7AC5"> &#160; <i class="fas fa-users"></i> Conference paper </em>
  
  
  
  
	<em class="Best Paper Award">
	  <em style="color:#F39C12"> &#160; <i class="fas fa-trophy"></i> Best Student Paper Award </em>
	</em>
  
  </span>

  <!-- Hidden abstract block -->
  

</div>

<!-- https://htmlcolorcodes.com/ -->
<!-- https://fontawesome.com/icons/graduation-cap?style=solid -->
</li></ol>

<h3 class="year">2017</h3>
<ol class="bibliography"><li>

<div id="3c977a8f81004ce093a4a4d5b2d710b0">
  
    <span class="title"><b>Advantages of using a biologically plausible embodied kinematic model for enhancement of speed and multifunctionality of a walking robot</b></span>
    <span class="author">
      
        
          
            <em>Mathias Thor</em>,
          
        
      
        
          
            
              Theis Strøm-Hansen,
            
          
        
      
        
          and
          
            
              Leon Bonde Larsen
            
          
        
      
    </span>

    <span class="periodical">
    
      <em>In Proceedings of the 2nd International Symposium on Swarm Behavior and Bio-Inspired Robotics (SWAM 2017)</em>
    
    
      2017
    

    </span>
  



  <span class="publication-links">
  
    <a class="abstract">Abstract</a>
  
  
  
    [<a href="/assets/pdf/SWARM2017_advanatages.pdf" target="_blank">PDF</a>]
  
  
  
  
  
  
  
  
  
    <em style="color:#AF7AC5"> &#160; <i class="fas fa-users"></i> Conference paper </em>
  
  
  
  
	<em class="Best Paper Award">
	  <em style="color:#F39C12"> &#160; <i class="fas fa-trophy"></i> Best Student Paper Award </em>
	</em>
  
  </span>

  <!-- Hidden abstract block -->
  
  <span class="abstract hidden">
    <p>A typical approach when designing a bio-inspired robot is to simplify an animal model and to enhance the functionality of interest. For hexapod robots, this often leads to models with an unknown performance; thereby influencing their functionality and requiring supplementary mechanics to become multifunctional. A preferable solution is to employ the embodied multifunctional capabilities of the animal as inspiration for robot design. For this reason, we present a method for translating the kinematic chain of a dung beetle, from which an accurate model and a simplified one were created and simulated. A comparison between the two modeling approaches shows a similar performance in regards to walking stability and accuracy, but differences when it comes to speed and multifunctionality. Here the accurate model outperforms the simplified model, by both walking faster and being capable of performing additional locomotory tasks. In conclusion, the accurate model of a dung beetle-inspired robot is advantageous in regards to multifunctional abilities including walking as well as standing on and rolling a ball, like a dung beetle.</p>
  </span>
  

</div>

<!-- https://htmlcolorcodes.com/ -->
<!-- https://fontawesome.com/icons/graduation-cap?style=solid -->
</li>
<li>

<div id="32ffbf42414c4cc28a5cbd5644d044e0">
  
    <span class="title"><b>Distributed Sensor-Driven Control for Bio-Inspired Walking and Ball Rolling of a Dung Beetle-Like Robot</b></span>
    <span class="author">
      
        
          
            
              Theis Strøm-Hansen,
            
          
        
      
        
          
            <em>Mathias Thor</em>,
          
        
      
        
          
            
              Leon Bonde Larsen,
            
          
        
      
        
          
            
              Emily Baird,
            
          
        
      
        
          and
          
            
              Poramate Manoonpong
            
          
        
      
    </span>

    <span class="periodical">
    
      <em>In Proceedings of the 2nd International Symposium on Swarm Behavior and Bio-Inspired Robotics (SWAM 2017)</em>
    
    
      2017
    

    </span>
  



  <span class="publication-links">
  
    <a class="abstract">Abstract</a>
  
  
  
    [<a href="/assets/pdf/SWARM2017_distributed.pdf" target="_blank">PDF</a>]
  
  
  
  
  
  
  
  
  
    <em style="color:#AF7AC5"> &#160; <i class="fas fa-users"></i> Conference paper </em>
  
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
  <span class="abstract hidden">
    <p>Bio-inspired robotics is an approach that looks at how nature solves a (complex) problem and applies the solution to a robot. Based on this approach, we have looked at walking animals that can exploit their legs for multiple functions, like locomotion and object manipulation/transportation. This is to expand the ability of walking robots. According to this, we have developed our robotic model based on a dung beetle, an animal that can walk and roll a dung ball using its legs. In this paper, we present distributed sensor-driven control for generating dung beetle-like walking and ball rolling behaviors of the developed model. The control mechanism is based on the Walknet bio-inspired controller. Furthermore, this paper gives a proof of concept that locomotion and object manipulation/transportation can be achieved without installing additional manipulators and/or grippers on a robot as shown by other works. To this end, the bio-inspired strategy can avoid the requirement of additional energy to power the manipulator or gripper system; thereby leading to an energy-efficient multi-functional robotic system.</p>
  </span>
  

</div>

<!-- https://htmlcolorcodes.com/ -->
<!-- https://fontawesome.com/icons/graduation-cap?style=solid -->
</li></ol>

<h3 class="year">2016</h3>
<ol class="bibliography"><li>

<div id="bachelor">
  
    <span class="title"><b>Embodied control of a dung beetle inspired hexapod</b></span>
    <span class="author">
      
        
          
            <em>M. Thor</em>,
          
        
      
        
          and
          
            
              T. Strøm-Hansen
            
          
        
      
    </span>

    <span class="periodical">
    
      <em>University of Southern Denmark - Campusvej 55, 5230 Odense, Denmark</em>
    
    
      2016
    

    </span>
  



  <span class="publication-links">
  
  
  
    [<a href="/assets/pdf/Bachelor.pdf" target="_blank">PDF</a>]
  
  
  
  
  
  
  
  
  
  
    <em style="color:#3498DB"> &#160; <i class="fas fa-graduation-cap"></i> Bachelor Thesis </em>
  
  
  
	<em class="Best Paper Award">
	  <em style="color:#F39C12"> &#160; <i class="fas fa-trophy"></i> Top grade </em>
	</em>
  
  </span>

  <!-- Hidden abstract block -->
  

</div>

<!-- https://htmlcolorcodes.com/ -->
<!-- https://fontawesome.com/icons/graduation-cap?style=solid -->
</li></ol>


  </article>

  

  

</div>

      </div>
    </div>

    <footer>

  <div class="wrapper">
    &copy; Copyright 2020 Mathias Thor.
    Hosted by <a href="https://pages.github.com/" target="_blank">GitHub Pages</a>.

	Last updated: January 24, 2020.</p>
  </div>

</footer>


    <!-- Load jQuery -->
<script src="//code.jquery.com/jquery-1.12.4.min.js"></script>

<!-- Load Common JS -->
<script src="/assets/js/common.js"></script>


<!-- Load KaTeX -->
<link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/KaTeX/0.9.0/katex.min.css">
<script src="//cdnjs.cloudflare.com/ajax/libs/KaTeX/0.9.0/katex.min.js"></script>
<script src="/assets/js/katex.js"></script>




<!-- Include custom icon fonts -->
<link rel="stylesheet" href="/assets/css/fontawesome-all.min.css">
<link rel="stylesheet" href="/assets/css/academicons.min.css">

<!-- Google Analytics -->
<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-XXXXXXXXX', 'auto');
ga('send', 'pageview');
</script>


  </body>

</html>
